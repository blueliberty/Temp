{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 了解比赛的背景知识，了解各个特征的含义，初步设想特征与预测目标的联系\n",
    "\n",
    "\n",
    "+ 基础模型\n",
    "  + 载入数据\n",
    "  + 观察数据\n",
    "  + 处理数据\n",
    "    + 处理缺失值\n",
    "    + 处理非数值型特征\n",
    "      + Sex列的处理\n",
    "      + Embarked列的处理\n",
    "  + 构建模型\n",
    "      + 用线性回归和CV拟合模型\n",
    "       + 计算预测错误率\n",
    "      + logistic回归\n",
    "  + 生成结果\n",
    "      + 处理测试集数据\n",
    "      + 生成提交结果\n",
    "      \n",
    "      \n",
    "+ 改进预测结果\n",
    "  + 改进模型\n",
    "      + 随机森林\n",
    "       + 调节参数\n",
    "  + 生成新特征\n",
    "      + 家庭成员数、姓名长度\n",
    "      + 头衔\n",
    "      + 家庭编号\n",
    "      + 特征选择\n",
    "  + 模型融合\n",
    "      + Gradient boosting\n",
    "  + 生成结果\n",
    "\t   + 处理测试集数据\n",
    "\t   + 对测试集进行预测\n",
    "\t   + 生成提交文件\n",
    "       \n",
    "       \n",
    "+ 最终的思考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 了解比赛的背景知识，了解各个特征的含义，初步设想特征与预测目标的联系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ PassengerId -- A numerical id assigned to each passenger.\n",
    "+ Survived -- Whether the passenger survived (1), or didn't (0). We'll be making predictions for this column.\n",
    "+ Pclass -- The class the passenger was in -- first class (1), second class (2), or third class (3).\n",
    "+ Name -- the name of the passenger.\n",
    "+ Sex -- The gender of the passenger -- male or female.\n",
    "+ Age -- The age of the passenger. Fractional.\n",
    "+ SibSp -- The number of siblings and spouses the passenger had on board.\n",
    "+ Parch -- The number of parents and children the passenger had on board.\n",
    "+ Ticket -- The ticket number of the passenger.\n",
    "+ Fare -- How much the passenger paid for the ticker.\n",
    "+ Cabin -- Which cabin the passenger was in.\n",
    "+ Embarked -- Where the passenger boarded the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺失值\n",
    "fillna方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = titanic.Age.fillna(titanic.Age.median(), inplace=True) # 暂时用中位数填充缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理非数值型特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前为止，有Name, Sex, Cabin, Embarked, Ticket这5列非数值型特征。其中cabin缺失值太多，Ticket和Name这两列暂时没有发现能够带来何种领域知识，因此这三列先不做处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Sex列的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.iloc - 支持整数索引 df.loc - 只支持标签索引 df.ix - 整数索引和标签索引都支持，但是在整数索引时会混淆，到底是面向位置还是面向标签\n",
    "titanic.ix[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1 # titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic.ix[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0 # titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "+ Embarked列的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic[\"Embarked\"].unique() # 观察Embarked列的值\n",
    "titanic.ix[titanic['Embarked'].isnull(), 'Embarked'] = 'S'\n",
    "titanic.ix[titanic['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic.ix[titanic['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic.ix[titanic['Embarked'] == 'Q', 'Embarked'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用线性回归和CV拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 计算预测错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783389450056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\n",
    "accuracy = (predictions == titanic[\"Survived\"]).mean()\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv('test.csv')\n",
    "_ = titanic_test['Age'].fillna(titanic_test['Age'].median(), inplace = True)\n",
    "titanic_test.loc[titanic_test['Sex'] == 'male', 'Sex'] = 0\n",
    "titanic_test.loc[titanic_test['Sex'] == 'female', 'Sex'] = 1\n",
    "_ = titanic_test['Embarked'].fillna('s', inplace = True)\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "_ = titanic_test['Fare'].fillna(titanic_test['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the algorithm class\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 改进预测结果\n",
    "+ Use a better machine learning algorithm.\n",
    "+ Generate better features.\n",
    "+ Combine multiple machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801346801347\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.fit(titanic[predictors], titanic[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0947804 ,  0.27493029,  0.24973985,  0.04436822,  0.04085351,\n",
       "        0.26367417,  0.03165354])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 调节参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820426487093\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成新特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 家庭成员数、姓名长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 头衔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Countess      1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Mme           1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].map(get_title)\n",
    "print pd.value_counts(titles)\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8,\n",
    "                 \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "\n",
    "titanic['Title'] = titles.map(title_mapping)\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print pd.value_counts(titanic[\"Title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 家庭编号\n",
    "由姓氏和家庭成员构成，再予以数字编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1      800\n",
      " 14       8\n",
      " 149      7\n",
      " 63       6\n",
      " 50       6\n",
      " 59       6\n",
      " 17       5\n",
      " 384      4\n",
      " 27       4\n",
      " 25       4\n",
      " 162      4\n",
      " 8        4\n",
      " 84       4\n",
      " 340      4\n",
      " 43       3\n",
      " 269      3\n",
      " 58       3\n",
      " 633      2\n",
      " 167      2\n",
      " 280      2\n",
      " 510      2\n",
      " 90       2\n",
      " 83       1\n",
      " 625      1\n",
      " 376      1\n",
      " 449      1\n",
      " 498      1\n",
      " 588      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "# A function to get the id given a row\n",
    "def get_family_id(row):\n",
    "    # Find the last name by splitting on a comma\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    # Create the family id\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    # Look up the id in the mapping\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
    "            current_id = max(family_id_mapping.values()) + 1\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "# Get the family ids with the apply method\n",
    "family_ids = titanic.apply(get_family_id, axis=1)\n",
    "\n",
    "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
    "family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
    "\n",
    "# Print the count of each unique id.\n",
    "print pd.value_counts(family_ids)\n",
    "\n",
    "titanic[\"FamilyId\"] = family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEsCAYAAAAIBeLrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaffafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811447811448\n"
     ]
    }
   ],
   "source": [
    "# 挑选出得分最高的4个特征\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "# 用随机森林建模\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "\n",
    "# 用3折CV计算正确率\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting\n",
    "+ Generally, the more diverse the models we ensemble, the higher our accuracy will be.\n",
    " + Diversity means that the models generate their results from different columns, or use a very different method to generate predictions.\n",
    "+ The classifiers we use have to be about the same in terms of accuracy. Ensembling one classifier that is much worse than another probably will make the final result worse.\n",
    "+ In this case, we'll ensemble logistic regression trained on the most linear predictors (the ones that have a linear ordering, and some correlation to Survived), and a gradient boosted tree trained on all of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = (predictions == titanic[\"Survived\"]).mean()\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('test.csv')\n",
    "_ = titanic_test['Age'].fillna(titanic_test['Age'].median(), inplace = True)\n",
    "titanic_test.loc[titanic_test['Sex'] == 'male', 'Sex'] = 0\n",
    "titanic_test.loc[titanic_test['Sex'] == 'female', 'Sex'] = 1\n",
    "_ = titanic_test['Embarked'].fillna('s', inplace = True)\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "_ = titanic_test['Fare'].fillna(titanic_test['Fare'].median(), inplace = True)\n",
    "\n",
    "# First, we'll add titles to the test set.\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8,\n",
    "                 \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "titanic_test['Title'] = titles.map(title_mapping)\n",
    "\n",
    "# Check the counts of each unique title.\n",
    "print pd.value_counts(titanic_test[\"Title\"])\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].map(lambda x: len(x))\n",
    "\n",
    "# Now we can add family ids.\n",
    "# We'll use the same ids that we did earlier.\n",
    "\n",
    "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
    "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
    "titanic_test[\"FamilyId\"] = family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int) # 最终必须转化为int，否则kaggle会判罚0分\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"titanic_dataquest_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最终的思考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There's still more work you can do in feature engineering:\n",
    " + Try using features related to the cabins.\n",
    " + See if any family size features might help -- do the number of women in a family make the whole family more likely to survive?\n",
    " + Does the national origin of the passenger's name have anything to do with survival?\n",
    "\n",
    "\n",
    "+ There's also a lot more we can do on the algorithm side:\n",
    " + Try the random forest classifier in the ensemble.\n",
    " + A support vector machine might work well with this data.\n",
    " + We could try neural networks.\n",
    " + Boosting with a different base classifier might work better.\n",
    "\n",
    "+ And with ensembling methods:\n",
    " + Could majority voting be a better ensembling method than averaging probabilities?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
